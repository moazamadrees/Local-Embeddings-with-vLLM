# UET Department RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot system for answering department-related questions from the UET Lahore prospectus. Built with local embeddings, ChromaDB vector storage, and Gemma-2 language model.

## ğŸ“ Project Overview

This project implements a complete RAG pipeline that:
- Extracts and processes text from UET prospectus PDF
- Generates embeddings using local sentence-transformers model
- Stores document chunks in ChromaDB vector database
- Implements guardrail layer to filter non-department questions
- Uses TinyLlama LLM for answer generation (open-source, no authentication required)
-- Provides FastAPI backend and Gradio frontend (recommended)

## ğŸ‘¥ Team Members & Task Division

### Khadija: Data Preprocessing Pipeline
- PDF text extraction using PyPDF2
- Text cleaning with regex
- Document chunking (500 words, 100-word overlap)
- Implementation of preprocessing modules
- FastAPI application with CORS
- REST API endpoints (/chat, /health, /stats)
- Error handling and logging
- Request/response models with Pydantic

### Moazam: RAG Engine & LLM Integration
- Vector retriever implementation
- vLLM/Transformers integration with Gemma-2
- Answer generation with citations
- Context formatting and prompt engineering
 - Gradio chat interface
- Test suite with 20 questions
- Automated testing script
- Documentation and video preparation

## ğŸ—ï¸ Architecture

### Data Preprocessing Pipeline
```
PDF Document â†’ Text Extraction â†’ Text Cleaning â†’ Chunking â†’ 
Embedding Generation â†’ Vector Storage (ChromaDB)
```

### System Architecture
```
User Query â†’ Streamlit Frontend â†’ FastAPI Backend â†’ 
Guardrail Validator â†’ Vector Retriever â†’ LLM Generator â†’ Response
```

**Architecture Diagrams:**
- [Preprocessing Pipeline](UET%20Department%20RAG%20System%20-%20Preprocessing.png)
- [System Architecture](UET%20Department%20RAG%20System%20-%20Architecture%20Diagram%20-%20visual%20selection.png)

## ğŸ“‹ Requirements

- **OS:** Windows
- **Python:** 3.11
- **GPU:** Optional (CUDA-enabled GPU recommended for faster inference)
- **RAM:** Minimum 8GB (16GB recommended)
- **Storage:** ~5GB for models and data

## ğŸš€ Installation

### Step 1: Create Virtual Environment
```powershell
cd c:\Users\moaza\Downloads\nlp_final
python -m venv venv
.\venv\Scripts\activate
```

### Step 2: Install Dependencies
```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 3: Install PyTorch with GPU Support (RTX 4050)
```powershell
pip uninstall torch torchvision torchaudio -y
pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118
```

**Models will download automatically on first run:**
- Embedding Model: sentence-transformers/all-MiniLM-L6-v2 (~90MB)
- LLM Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0 (~1.1GB) - No authentication required!

## ğŸ“Š Running the Project

### Step 1: Preprocess the PDF (One-time)
```powershell
python -m backend.preprocessing.run_pipeline
```

### Step 2: Start API Server
```powershell
python -m uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

### Step 3: Start Frontend (New Terminal)

**Gradio (Recommended)**
```powershell
.\venv\Scripts\activate
python frontend/gradio_app.py
```
Open http://localhost:7860 in your browser.

If you prefer Streamlit the project still contains `frontend/app.py` but Gradio is the maintained UI.

## ğŸ§ª Testing

```powershell
python tests/run_tests.py
```

Tests all 20 questions and generates results in `tests/test_results.json`.

## ğŸ“ Project Structure

```
uet-rag-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # FastAPI application
â”‚   â”œâ”€â”€ config.py                    # Configuration settings
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py         # PDF text extraction
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py          # Text cleaning with regex
â”‚   â”‚   â”œâ”€â”€ chunker.py               # Text chunking
â”‚   â”‚   â”œâ”€â”€ embedder.py              # Embedding generation
â”‚   â”‚   â”œâ”€â”€ vector_store.py          # ChromaDB interface
â”‚   â”‚   â””â”€â”€ run_pipeline.py          # Pipeline orchestration
â”‚   â”œâ”€â”€ guardrail/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ scope_validator.py       # Question scope validation
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ retriever.py             # Vector retrieval
â”‚       â”œâ”€â”€ llm_client.py            # LLM integration
â”‚       â””â”€â”€ answer_generator.py      # Answer generation
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                       # Streamlit GUI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ UET lahore Document.pdf  # Source document
â”‚   â”œâ”€â”€ processed/                   # Processed text (generated)
â”‚   â””â”€â”€ chroma_db/                   # Vector database (generated)
â”œâ”€â”€ diagrams/
â”‚   â”œâ”€â”€ preprocessing_pipeline.png
â”‚   â””â”€â”€ system_architecture.png
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_queries.json            # 20 test questions
â”‚   â”œâ”€â”€ run_tests.py                 # Automated test runner
â”‚   â””â”€â”€ test_results.json            # Test results (generated)
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ VIDEO_SCRIPT.md                  # Video presentation script
â”œâ”€â”€ .env.example                     # Environment variables template
â””â”€â”€ .gitignore                       # Git ignore rules
```

## ğŸ”§ Technical Stack

- **Python:** 3.11
- **Embeddings:** sentence-transformers/all-mpnet-base-v2 (default)
- **LLM:** TinyLlama/TinyLlama-1.1B-Chat-v1.0 (1.1GB, open-source)
- **Vector DB:** ChromaDB
- **API:** FastAPI
- **UI:** Gradio (recommended)

## ğŸ“ License

Educational project for NLP class.
